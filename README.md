# ğŸ§  Web Article Sentiment Analyzer

> ğŸ“Š A complete pipeline for scraping web articles, performing sentiment and readability analysis, and exporting results to Excel.

---

## ğŸ“Œ Overview

This project automates the process of:
1. **Scraping** content from URLs using Playwright.
2. **Analyzing** text for sentiment and readability using NLTK-based NLP techniques.
3. **Generating** structured output with various metrics such as:
   - Positive/Negative scores
   - Subjectivity/Polarity
   - Readability scores (Fog Index, Avg. Sentence Length, etc.)

All you need is a list of article URLs in Excel format!

---

## ğŸ§° Tech Stack

- ğŸ Python 3.9+
- ğŸ“œ NLTK
- ğŸ•¸ï¸ Playwright
- ğŸ“ˆ Pandas
- ğŸ“ Excel I/O

---

## ğŸ—‚ï¸ Project Structure

```bash
ğŸ“¦project_root
â”œâ”€â”€ main_execution.py         # ğŸš€ Main pipeline execution script
â”œâ”€â”€ web_scraper.py            # ğŸŒ Scrapes web articles
â”œâ”€â”€ text_analysis.py          # ğŸ§  Performs sentiment and readability analysis
â”œâ”€â”€ config.py                 # âš™ï¸ Configuration and directory setup
â”œâ”€â”€ Input.xlsx                # ğŸ“¥ Input URLs (with URL_ID and URL columns)
â”œâ”€â”€ Output.xlsx               # ğŸ“¤ Final results (auto-generated)
â”œâ”€â”€ extracted_texts/          # ğŸ“„ Scraped text content
â”œâ”€â”€ StopWords/                # âŒ Stop words text files
â”œâ”€â”€ MasterDictionary/         # ğŸŸ¢ Positive and ğŸ”´ Negative word lists
```

---

## âœ… Requirements

Install Python 3.9+ and then install the following dependencies:

```bash
pip install pandas nltk openpyxl playwright
python -m playwright install
```

Additionally, NLTK resources are automatically downloaded on the first run.

---

## â–¶ï¸ How to Run

### Step 1: Prepare Input
Add URLs in an Excel file `Input.xlsx` with the following columns:
- `URL_ID` â€” Unique ID for each article
- `URL` â€” Full article URL

### Step 2: Run the Pipeline

```bash
python main_execution.py
```

This will:
1. Optionally scrape articles (uncomment the scraper section in `main_execution.py` if needed).
2. Analyze text files in the `extracted_texts/` folder.
3. Generate `Output.xlsx` with results.

---

## ğŸ“Š Output Features

Each analyzed article will have:
- `positive_score`, `negative_score`
- `polarity_score`, `subjectivity_score`
- `average_sentence_length`, `percentage_of_complex_words`
- `fog_index`, `syllables_per_word`
- `personal_pronouns`, `avg_word_length`
- And more...

---

Run analysis:
```bash
python main_execution.py
```

---

## ğŸ’¡ Notes

- Ensure `StopWords` and `MasterDictionary` folders are populated with appropriate `.txt` files (e.g., `positive-words.txt`, `negative-words.txt`, etc.).
- Scraping is based on typical article structures, but may need adjustment for non-standard websites.

---

## ğŸ“„ License

This project is open-source and free to use under the MIT License.
